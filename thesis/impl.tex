\chapter{Design \& Implementation}\label{sec:impl}

\section{Bitwidth analysis}
The analysis is a data flow analysis. The analysis attaches a $(int,boolean)$ tuple to every meaningful node. A node is considered meaningful is the node has a integer style mode. We will reference the first value as \emph{stable bits} and the second bit as \emph{is positive}.

\paragraph{Bit representation}
The stable bits are indicating how many bits are stable, and therefore not used.
The second value of the tuple indicates if the value will ever reach negative numbers or not. And thus indicate at least one stable bit at the highest position. However, the second value is only meaningful for modes that allow signs.

\paragraph{Range representation}
There is also a second way of interpreting the two values. The stable bits can define a minimum and maximum range. The maximum number is reached if the stable bits are just always zero. If the mode is signed and the node is not positive, then the minimum number is reached by assuming all stable bits are one. Otherwise the minimum range is 0. We can define the following min max definitions for the ranges:

$
max_{bitwidth}(x)=
\left\{
\begin{array}{l}2^{stable\_digits-1}-1\\2^{stable\_digits}-1\end{array}
\begin{array}{l} {mode.signed} \\ {Otherwise} \end{array}
\right.
$

$
min_{bitwidth}(x)=
\left\{
\begin{array}{l}2^{stable\_digits-1}\\0\end{array}
\begin{array}{l} {mode.signed and is_positive} \\ {Otherwise} \end{array}
\right.
$

\input{fig/lattice.tex}

\paragraph{Analysis} The analysis works as a fixed point iteration. Therefore we use  \ref{fig:lattice} as lattice. The values of the lattice are representing the tuples from the analysis.

As a first step, we iterate over every single node and initialize the node with $\top$ and mark it as \textit{dirty}. If the node is constant, we calculate its bitwidth. Nodes with the opcodes \textit{Const}, \textit{Size} and \textit{Address} are considered constant.

The second step consists of recalculating every \textit{dirty} node in the graph. if $node.bitwidth < computed\_bitwidth$, the computed bitwidth is memorized as the new bitwidth of the node and every successor of the node is marked as dirty. The used rules for recalculating the nodes are described in REFERENCE TO TABLE %TODO.

\subsection{Definition: Value prediction}
In addition to the normal analysis results, the fixed point iteration can insert additional 
confirm nodes. Those confirm nodes help making the analysis more accurate.
First of all we need a few definitions for easier understanding:

\subparagraph{Definition: True / false Blocks}
%TODO

\subparagraph{Definition: Upper bounds}
\input{fig/upper_bound_cmp.tex}
A compare node is defining a upper bound if $node.relation = <$ and the node at $node.right$ is constant. For nodes where this is given we define
\emph{$\omega := node.left$} and the \emph{true block is called $\iota$}. A visualization of the definition is given at \ref{fig:compare_upper_bound}.
A compare node is also defining a upper bound if it can be transformed into a construct that matches the definition. For example with switching the right and left nodes, while turning the relation.
\subparagraph{Definition: Predecessor in a certain block}
\begin{center}
$\phi(a, b) := \forall X \prec a \wedge X.block = b$ 
\end{center}
$\phi$ returns every node that is a direct predecessor of a and located in block b.
\subparagraph{Definition: Constant dependencies}
\begin{center}
$\xi(a) := 
\left\{
	\begin{array}{l}
		a \cap \xi(c)\\ 
		\emptyset
	\end{array}
	\begin{array}{l}
		, \text{If there is only one not constant dependency \textit{c}} \\ 
		, \text{otherwise}.
	\end{array}
\right.$
\end{center}

If \textit{a} has only one not constant dependency node c, then $\xi$ returns the element a and $\xi(c)$. Otherwise it returns a empty set.

\paragraph{Upper bounds for block execution}
The values that are calculated in a node are (even if the fixed point iteration is not stable yet) possible values. The iteration starts at $\top$ and moves into the direction of $\bot$. This means that our range of possible values starts at something like $[0,0]$, moving towards $[n,-n]: n > 0 n <= max(mode)$ with each iteration. For a $\omega$ node this means that there can be a a recalculation, (new and old bitwidth is notated as the value range $\hat{x}$ and $x$) where the compare relation is true for $x$ but not anymore for  $\hat{x}$. This means that $\hat{x}$ is the upper bound for $\iota$. Thus we can insert a confirm node between every node $e \in \phi(\omega, \iota)$ and $\omega$.

\paragraph{Moving upper bounds backwards}
The confirms we have inserted between $\omega$ and its successors are not the only thing we can insert. We can also insert a confirm node between every $\phi(\xi(\omega), \iota)$. Important here is, the predecessors of $\omega$
Those confirms are then also inserted above conversation nodes, which is not possible using the normal construct insertion code provided by \libFIRM


\subsection{Difference to VRP}

There is already a analysis that is doing something similar, it is called value range propagation. The difference from VRP to BA is that in VRP each iteration is trying to predict the exact range after each operation. While BA tries to predict the unused bits after each operation. This little detail is mainly showing up in speed of the fixed point iteration, VRP converges way slower than BA. Details for this are given in the evaluation chapter \ref{sec:eval}.

\section{Stable Conversion nodes}
A conversion of a data word can result in two different results. First the bitwise representation stays the same. Second, the bitwise representation also gets mapped.
We call the first case \textit{Stable Conversion node}.

\paragraph{Finding stable conversion nodes}
Stable conversion nodes can be found using the bitwidth analysis. As described before, the analysis maps every node in the tree to a tuple. First number is the number of stable bits, which describes a upper bound for the numbers that will be written into the data word. The second number is a boolean flag and indicates if the number is going to be greater than 0 or not. If we now can see that the number range from the successor is the same as the one of the conversion node, then we can declare the conversion as stable.

\paragraph{Removing conversion nodes}
In case we found a stable conversion node, then we can say that this node only exists for syntax rules, there is no semantical value in them. Removing those nodes also has the advantage of helping other analysis. The confirm insertion algorithm of \libFIRM is searching for assertions that can be made based on looking at compare nodes. This works quite well. However, a construction like TODO does not work.
%FIXME diagram 
%FIXME reason
After removing the conversion node, the analysis can find a assertion based on the compare node. This also helps the branch prediction, dead code elimination. \newline
However, for really removing the conversion nodes, we need to find situations where we can eliminate the conversion node. One was already seen in the example. A compare node with a constant node as second operand. Another situation is a arithmetical operation with a constant and conversion node as operands.

\paragraph{Compare-Conversion optimization}
%FIXME diagram
\paragraph{Arithmetical-Conversion optimization}
%FIXME diagram