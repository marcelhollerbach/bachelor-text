\chapter{Basics}\label{sec:basics}

\section{cparser / libfirm}
Modern compilers are now developed for over half a century. Over the time a new structure has evolved. Compilers are split into three parts. The first part is called \textit{front end} and handles everything related to the language specific parts. The second part is called \textit{middle ware} and handles the abstract notation of code execution. The last part is called \textit{back end} and does the translation into something like assembler or java bytecode. As an example, cparser is handling the C specific tasks. The parsed c code is then translated into a control flow graph from $\libFIRM$, which is the middle ware. The $\libFIRM$ middle ware then also acts as back end and translates the control flow graph into assembler / java bytecode.

\paragraph{Control flow graph in \libFIRM} The interaction between the front and middle ware is based on a data structure similar to a control flow graph, it is called FIRM graph. A FIRM graph is a directed graph. Each node is a operation. Nodes can have operands. We say that a node always depends on another node, when there is a edge from the node to the other node. The FIRM graphs are also the base structure for analyzing the control flow of a software. Such a analysis is called control flow analysis. The nodes of the FIRM graph can have be categorized in different types: control flow, arithmetical operations, memory handing, constant expressing. A node is additionally placed in a block. A node is executed if all its operands have been executed. Or, if there are no operands, when its block is executed.
Another software that does the same thing is \textit{clang}, where the back end is handled by \textit{llvm}.
A more in detail explanation can be found in \cite{libfirm}. A more theoretical and abstracted introduction to control flow graphs can be found in \cite{control-flow-analysis}

\paragraph{Confirm nodes in \libFIRM}
In $\libFIRM$ there are several node types, one of them is called "Confirm" node. A Confirm node does not have a hardware representation. A confirm node has 2 operands. They are called value and bound, additionally a Confirm node has a relation. As relations $\not=$, $=$, $<$, $>$, $>=$, $<=$ are possible. 
Written as prefix notation we can say that the Confirm node gives the assertion that $\tau(value, bound)$ is true, where $\tau$ is the relation. This is useful for control flow analysis, as the Confirm nodes can indicate possible shortcuts with knowledge that is gained from other analysis.

\subparagraph{True / false Blocks}
\input{fig/basic_compare.tex}
A compare node in $\libFIRM$ has always a relation, 2 operands and 2 blocks. The compare node executes the true block, when the relation and operands are evaluating to true. The false block is executed otherwise. The structure is visualized in \autoref{fig:compare}

\paragraph{Interaction from front to back end}

\begin{figure}
	\centering
	\begin{lstlisting}[frame=single]
	#include <stdlib.h>
	#include <stdio.h>
	
	int main(int argc, char const *argv[]) {
	  printf("Hello Firm!");
	  return 0;
	}
	\end{lstlisting} 
	\caption{Sample source code}
	\label{code:workflow:example}
\end{figure}

As an example, we want to compile the program code from \autoref{code:workflow:example}.
First of all, the front end parses the given source code. The parsed code then is transformed into a abstract syntax tree (AST). The representation in the abstract syntax tree encodes the syntactical informations from the software. File contents like curly are encoded in the structure, and are not explicitly represented in the AST. \newline
After that the AST is transformed into a FIRM graph. \newline
At this point the front end handed the informations for creating a binary programm to the back end. However, the front end can now tell the back end to perform optimizations on the FIRM graph. In terms of C, this is often controlled with the -O{1,2,3} flags. \newline
After the optimizations have taken place, the binary files are written into a file, and the compiler call is finished.
\begin{figure}
	\centering
	\begin{tabular}{c | c c c c c c c c c}
		value & 7 & 6 & 5 & 4 & 3 & 2 & 1 & 0 \\
		\hline
		5     & 0 & 0 & 0 & 0 & 0 & 1 & 0 & 1 \\
		-2    & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 0 \\
	\end{tabular}
	\caption{Number representation}
	\label{fig:numbers}
\end{figure}
\paragraph{Number representation}
So-called \textit{modes} are used in $\libFIRM$ to categorize data words. A mode specifies a length in bits. A data word can have a sort, this can be \textit{integer}, \textit{float}, \textit{reference}, \textit{data} and \textit{boolean}. For us, the only interesting type is the integer type, since this is the only type where we can compute bitwidth for now. Those integer-modes can be signed or unsigned. The length of the mode defines the maximum number. If it is signed, then it also defines the minimum number. Otherwise the minimum is just zero. The sign is encoded using two's complement. There are the following integer modes : 
%\textit{mode\_Bs}:
\textit{int8},
%\textit{mode\_Bu}: 
\textit{uint8},
%\textit{mode\_Hs}: 
\textit{int16},
%\textit{mode\_Hu}: 
\textit{uint16},
%\textit{mode\_Is}: 
\textit{int32},
%\textit{mode\_Iu}:
\textit{uint32},
%\textit{mode\_Ls}: 
\textit{int64},
%\textit{mode\_Lu}:
\textit{uint64},

As an example, in \autoref{fig:numbers} two numbers are displayed with its hardware representation.
The term \textit{mode} is used to describe integer-modes for the rest of this thesis.


\section{Software theory}

There are a few mathematical basics which are known to be useful for performing compiler analysis. The first basic is the lattice. The second basic is the fixed point iteration.

\subsection{Lattice}

A lattice is an algebraic structure. For a lattice $L=(V,\sqcup,\sqcap)$, there are the following rules:

\begin{itemize}
	\item $\sqcup: V \times V \rightarrow V$ returns the smallest element, that is bigger or equal than the two operands
	\item $\sqcap: V \times V \rightarrow V$ returns the biggest element, that is smaller or equal than the two operands
%	\item $\forall a,b \in V : \exists a \sqcup b \wedge \exists a \sqcap b$
	\item $\forall u,v \in V : u \sqcup ( u \sqcap v) = v \wedge u \sqcap ( u \sqcup v ) = v$
\end{itemize}

Additionally we add te requirement of $|V| \not= \infty$. This is not a requirement for lattices in general. However, for fixed point iterations this requirement is precise enough.

The element, which is the least of all elements is called $\bot$. The greatest of all is called $\top$. A lattice can also be written down as a Hesse diagram, which can be seen in \autoref{fig:lattice}

A more detailed introduction can be found in \cite{lattice_theory}.

\subsection{Fixed point iteration}
Fixed point iteration is a method for finding a $x$ where we know that $f(x)=x$. \newline
First of all we define $f: D \rightarrow D$. $f$ is monotone, additionally $|D|$ must be finite. We call $x \in D$ a fixed point if $f(x)=x$.
For iterating we start with the minimum of D. We define $y_0=f(min(D))$, $y_i=f(y_{i-1})$. With the requirements from above we can say: $\exists i \in N : y_i = y_{i-1}$. For further reading, please see \cite{fixed-point-iteration-basic}

%\paragraph{Prove}$f$ is continuous, this means $\forall x >= y: f(x) >= f(y)$. So we know that $f(x) = y$ where $y > x$. Or $f(x) = x$, which means that we found a fixed point. However, the first case can only happen a finite amount of times, since $|D| \not= \infty$. Thus there has to exist a fixed point.

\paragraph{Data flow analysis}
We can adapt the fixed point iteration to work on a CFG. For the following we define additionally:
\begin{itemize}
	\item CFG is called $G=(V,E)$
	\item The lattice we use is called $L$
	\item $f _{node}:L \rightarrow L$ is the function for iterating on a single node. $f _{node}$ is monotonous.
	\item $D$ is a set, where we can say that: $\forall d \in D: d = \{(0, v_0), ... , (n, v_n)\}$
	\item $f(d) := \{(id, \hat{v})| (id, v) \in d \wedge f _{node}(v) = \hat{v}\}$
\end{itemize}

We start the iteration with $d_{bot} := \{(0,\bot), ..., (n, \bot)\}$. At some point, while continuing the iteration, we will find a $\hat{d} = f(\hat{d})$. 

%\paragraph{Prove}: $|D|$ consists of every possible configuration. There is only a finite amount of elements in the lattice. Thus we can say that $|D|=2^m$. \newline
%We say $d_1 <= d_2 \equiv \forall (id_2, v_2) \in d_2: \forall (id_1, v_1) \in d_1 : v_2 >= v_1$. $f_{node}$ is continuous. \newline
%f being not continuous means $\exists x <= y: f(x) > f(y)$.
%This means that there has to be a $v_x \in x$ and $v_y \in y$, where $f_{node}(v_x) > f_{node}(v_y)$ even if $v_x <= v_y$, which is against the definition of $f_{node}$. Thus f has to be continuous.

\section{Software basic}
\subsection{Worklist algorithm}

A possible solution for implementing fixed point algorithms could be done by iterating the whole CFG everytime a node changes. However, this is quite wasteful, since we know that the state of a node only depends on the state of its operands. Therefore a algorithm called \textit{worklist algorithm} has evolved and can be found in \autoref{worklist}.

\begin{algorithm}[H]
	worklist := {CFG.Nodes}\;
	\While{worklist not empty}{
		node := worklist.pop()\;
		node\_changed := recalc(node)\;
		\If{node\_changed}{
			\ForEach{operand $\in$ node.operands}{
				\If{!worklist.contains(operand)}{
					worklist.appi jend(operand)	
				}
			}
		}
	}
	\caption{Worklist alogithm}
	\label{worklist}
\end{algorithm}

The base idea is to maintain a worklist which contains all nodes that are dirty. A node is considered dirty, when its operands have changed, but the node itself is not recalculated. Additional informations can be found at \cite{iterative-data-flow-analysis-revisited}
%http://cseweb.ucsd.edu/classes/sp00/cse231/report/node12.html