\chapter{Evaluation}\label{sec:eval}

For this thesis, libjpeg, libpng and libgif and zlib are evaluated. zlib is often use as a general purpose lossless compression. The other libraries are used for decoding the most used image formats.

For those projects we are measure two things. 
First we check how much bitwidth is really used, compared to the full modes. Additionally, we check what impact this has on our assembler generation.
Second, we are checking if the saved bitwidth does impact the VHDL outputting of \textit{firm2vhdl}, this is done by compiling the generated VHDL files with two different FPGA-IDEs.

\section{General bitwidth}
%How much bitwidth the nodes are having in average per function
A node in $\libFIRM$ uses an amount of bits, the maximum is defined by the mode. We note down the bitwidth of a node as $bitwidth_{irn}(n)$.
If we don't perform our analysis, then we need to assume the worst case, the node uses all the bits that are available from its mode.
If the analysis is performed, then we can say that the stable bits of the analysis defines the bitwidth of a node.
For comparing the functions directly, we define:

$bitwidth_{irg}(irg) := \frac{\sum\nolimits_{n \in irg.nodes} bitwidth_{irn}(n)}{|irg.nodes|} $ 

We divide the sum by the number of nodes, to be able to compare smaller graphs with bigger ones. 

\paragraph{Const nodes}
\input{fig/table_const.tex}
While evaluating the projects, it came up that a normal graph consists of a lot of constant nodes, exact ratio can be found in the third column of  \autoref{table:amount_const}. 

The problem with a Constant node is that the bitwidth can be quite low, while this does not improve the assembler generation, nor impact the overall usage of registers.

Calculating how much bitwidth a constant takes is anyway only the matter of a log2(...) call, which is not really interesting to evaluate, in order to see how good the analysis works.

Summed up, Constant nodes are sophisticating the bitwidth of a function a lot. Thus the statistics at \ref{table:project_average_bitwidth} are divided into results with and without the constant values.

\paragraph{Project results}
\input{fig/project_average_bitwidth.tex}
In \autoref{table:amount_const} the second column shows the total number of nodes that were created in order to compile the library. This can be used as some sort of complexity metric. 
\autoref{table:project_average_bitwidth} shows that all the libraries except \textit{libjpeg} have a similar amount of bitwidth that got saved. However, the amount of saved bitwidth still does not really correlate with the complexity of the projects, since \textit{libgif} is not similar complex to \textit{zlib} or \textit{libpng}.\newline
We can say that we save up about 9 bits in average per node.

\section{Optimizations on assembler output}

In this section we compare the shared object files of the library. The first run was done with plain cparser, the second run was done with cparser + the patches created for this thesis.\newline
After that the disassemblies of the shared object files are compared. However, comparing those two shared object files is quite hard, due to changes in addresses and instruction order. Making the comparing easier was possible after removing the address of every line and removing the arguments of the instructions. Loosing the arguments of the instruction makes it hard to compare if something in the calling of the function has changed. However, we can better study the raw changes on the instructions. What follows is the explanation how the assembler output changes.

\paragraph{libgif} There was not a single change, the two binary files are identical.
\paragraph{libjpeg} The assembler output from after the optimization is about 30 instructions longer. The functions don't differ a lot. It looks most of the times like simple reordering of instructions. The amount of additional instructions is probably caused by loop unrolling.

\paragraph{libtiff} The results here are similar to libjpeg. One difference is, the optimization causes add instructions to be translated to lea instructions. 

\paragraph{libpng} libpng seems to be different here. The assembly file after the optimization is shorter than before, by 10 instructions. Instructions that are removed are mainly mov instructions.

\paragraph{zlib} zlib is similar to libpng. The file gets 3 lines shorter, which is not much. The rest of the binary differences are basically instruction order changes.

The complete repository with the releases and data and scripts can be found at \footnote{\url{https://github.com/marcelhollerbach/bachelor-data}}.

\section{Optimization VHDL improvements}

\input{fig/code_snippet.tex}
We use the code at \autoref{code:vhdl-eval} for evaluating the VHDL generation improvements. The saved bitwidth from the analysis can be observed in \autoref{code:vhdl-eval-table}. The unoptimized VHDL code has a summed bitwidth usage of 928, while we drop this usage down to 609 when optimized. This means on a average base unoptimized $25.1$ and optimized $16.91$.

After the C snipped was compiled into VHDL, the Xilinx Vivado 2018.2 IDE for FPGA generation was used to compile the VHDL code into a bitstream. A second try was done to compile the VHDL with Quartus. Quartus is a FPGA SDK from Intel Altera.

\paragraph{Vivado}
In Vivado two projects of the same kind have been created, one with the VHDL file without the improved \textit{ir2vhdl} tool, one with them. Both projects have been using the Kintex UltraScale+ xcku5p device. After the syntesis was running on both projects we took the statistic table from the report. We compared the number of LUTs and registers. 
\input{fig/vhdl_cmp_table_vivado.tex}
In \autoref{table:vhdl_improvements_vivado} you can observe in the first two columns that the unoptimized code has a much lower number of LUTs and registers.
A quick look at the optimized VHDL code shows that there are a lot of redundant \textit{resize} calls. After that observation the decision was made that the redundant calls can be removed by hand right now, as from the beginning on we thought the VHDL compiler would take care of removing those. The results of this third try can be observed in the last column.
All in all this was not improving the results at all. A deeper look showed that redundant resize calls are not handled by this VHDL compiler. Even after removing them, the amount of LUTs was still bigger than in the beginning.

\paragraph{Quartus}
As in Vivado two projects have been created. Both projects are using the Board Intel Altera Cyclone V as their target device. After the "Compiling and Fitting" build step, the two "Resource Usage Reports" have been compared.
\input{fig/vhdl_cmp_table_quartus.tex}
What can be observed in \autoref{table:vhdl_improvements_quartus} is that the optimization does not impact the numbers of ALMs used. The hand optimized code was resulting in the equal results as the optimized VHDL output, and is not explicitly listed therefore. Quartus provides an additional setting where the "Compiling and Fitting" steps are more focused on performance or area usage. Tweaking those setting did not impact the differences between the two generated VHDL files.

Overall we can see that it's quite hard to measure the improvements the VHDL optimization gives, due to the missing insight into the processes that are performed in order to compile a VHDL file into a bitstream.