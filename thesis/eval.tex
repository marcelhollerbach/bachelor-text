\chapter{Evaluation}\label{sec:eval}

The most interesting projects for evaluating the implementation, are decoding softwares that are transforming a binary blob into a image. For this purpose, libjpeg, libpng and libgif are evaluated. Additionally zlib is done, since it is a general purpose library for lossless compression, which is often used in reallife products.

For those projects we are measuring two things. First, how effective our bitwidth saving is and how much we have saved. Second, we are trying to compare the assembler with and without the applied optimizations.

\section{General bitwidth}
%How much bitwidth the nodes are having in average per function
A node in $\libFIRM$ uses a amount of the available bitwidth. We note down the bitwidth of a node as $bitwidth_{irg}(n)$.
If we don't perform our analysis, then we need to assume the worst case, the node uses all the bits that are available from its mode.
If the analysis is performed, then we can say that the stable bits of the analysis are defining the bitwidth of a node.
For comparing the functions directly, we define:

$bitwidth_{irg}(irg) := \frac{\sum\nolimits_{n \in graph.nodes} bitwidth_{irn}(n)}{|graph.nodes|} $ 

We divide the sum by the number of nodes, to be able to compare smaller graphs with bigger ones. 

\paragraph{Const nodes}
\input{fig/table_const.tex}
While evaluating the projects, it came up that a normal graph consists of a lot of constant nodes, exact percentages can be found in the third column of  \autoref{table:amount_const}. 

The problem with a Constant node is, the bitwidth can be quite low. While the constant does not matter on hardware in most cases, since they are decoded directly in a hardware instruction. Additionally they don't take up any additional space in VHDL. 

Calculating how much bitwidth a constant takes is anyway only the matter of a log2(...) call, which is not really interesting to evalulate, in order to see how good the analysis works.

Summed up, Constant nodes are sophisticating the bitwidth of a function a lot. Thus the statistics later are divided into results with and without the constant values.

\paragraph{Project results}
\input{fig/project_average_bitwidth.tex}
In \autoref{table:amount_const} the second column is showing the total number of nodes that got created in order to compile the library. This can be used as some sort of complexity metric. 
\autoref{table:project_average_bitwidth} shows that all the libraries except \textit{libjpeg} have a similar amount of bitwidth that got saved. However, the amount of saved bitwidth still does not really correlate with the complexity of the projects, since \textit{libgif} is not similar complex to \textit{zlib} or \textit{libpng}.\newline
We can say that we safe up about 9 bits in average per node.

\section{Optimizations on assembler output}

In this section we compare the shared object files of the library. The first run was done with plain cparser, the second run was done with cparser + the patches created for this thesis.\newline
After that the disassembly of the shared object files are compared. However, comparing those two shared object files is quite hard, due to addresses and instruction order changes. Making the comparing easier was possible after removing the address of every line and removing the arguments of the instructions. Loosing the arguments of the instruction makes it hard to compare if something in the calling of the function has changed. However, we can better study the raw changes on the instructions. What follows is the explanation, how the assembler output changes.

\paragraph{libgif} There was not a single change, the two binary files are identical.
\paragraph{libjpeg} The assembler output from after the optimization is about 30 instructions longer. The functions don't differ a lot. It looks most of the times like simple reordering of instructions. The amount of additional instructions is caused by instruction duplication, which can be caused by loop unrolling.

\paragraph{libtiff} The results here are similar to libjpeg. One difference is, the optimization causes add instructions to be translated to lea instructions. 

\paragraph{libpng} libpng seems to be different here. The assembly file after the optimization is shorter than before, by 10 instructions. Instructions that are removed are mainly mov instructions.

\paragraph{zlib} zlib is similar to libpng. The file gets 3 lines shorter, which is not much. The rest of the binary differences are basically instruction order changes.

The complete repository with the releases and data and scripts can be found at (FIXME)

\section{Optimization vhdl improvements}
%